name: Speech_To_Text_HF_Finetuning_using_HF_Datasets
init_from_nemo_model: null
init_from_pretrained_model: null
model:
  sample_rate: 16000
  data_path: google/fleurs
  data_name: te_in
  streaming: false
  audio_key: audio.array
  sample_rate_key: audio.sampling_rate
  text_key: text
  normalize_text: true
  symbols_to_keep:
  - .
  train_ds:
    manifest_filepath: hugginface
    streaming: ${model.streaming}
    normalize_text: true
    symbols_to_keep: ${model.symbols_to_keep}
    audio_key: ${model.audio_key}
    sample_rate_key: ${model.sample_rate_key}
    text_key: transcription
    hf_data_cfg:
      path: google/fleurs
      name: te_in
      split: train
      streaming: false
    sample_rate: ${model.sample_rate}
    batch_size: 16
    shuffle: true
    shuffle_n: 2048
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
  validation_ds:
    manifest_filepath: hugginface
    streaming: ${model.streaming}
    normalize_text: true
    symbols_to_keep: ${model.symbols_to_keep}
    audio_key: ${model.audio_key}
    sample_rate_key: ${model.sample_rate_key}
    text_key: transcription
    hf_data_cfg:
      path: google/fleurs
      name: te_in
      split: validation
      streaming: false
    sample_rate: ${model.sample_rate}
    batch_size: 8
    shuffle: false
    shuffle_n: 2048
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
  test_ds:
    manifest_filepath: hugginface
    streaming: ${model.streaming}
    normalize_text: true
    symbols_to_keep: ${model.symbols_to_keep}
    audio_key: ${model.audio_key}
    sample_rate_key: ${model.sample_rate_key}
    text_key: transcription
    hf_data_cfg:
      path: google/fleurs
      name: te_in
      split: test
      streaming: false
    sample_rate: ${model.sample_rate}
    batch_size: 8
    shuffle: false
    shuffle_n: 2048
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
  char_labels:
    update_labels: false
    labels: null
  tokenizer:
    update_tokenizer: true
    dir: tokenizers/tokenizer_spe_bpe_v256
    type: bpe
  spec_augment:
    _target_: nemo.collections.asr.modules.SpectrogramAugmentation
    freq_masks: 2
    time_masks: 10
    freq_width: 27
    time_width: 0.05
  optim:
    name: adamw
    lr: 0.0001
    betas:
    - 0.9
    - 0.98
    weight_decay: 0.001
    sched:
      name: CosineAnnealing
      warmup_steps: 5000
      warmup_ratio: null
      min_lr: 5.0e-06
trainer:
  devices: -1
  num_nodes: 1
  max_epochs: 100
  max_steps: -1
  val_check_interval: 1.0
  accelerator: auto
  strategy:
    _target_: lightning.pytorch.strategies.DDPStrategy
    gradient_as_bucket_view: true
  accumulate_grad_batches: 1
  gradient_clip_val: 0.0
  precision: 32
  log_every_n_steps: 10
  enable_progress_bar: true
  num_sanity_val_steps: 0
  check_val_every_n_epoch: 1
  sync_batchnorm: true
  enable_checkpointing: false
  logger: false
  benchmark: false
exp_manager:
  exp_dir: null
  name: ${name}
  create_tensorboard_logger: true
  create_checkpoint_callback: true
  checkpoint_callback_params:
    monitor: val_wer
    mode: min
    save_top_k: 5
    always_save_nemo: true
  resume_if_exists: false
  resume_ignore_no_checkpoint: false
  create_wandb_logger: false
  wandb_logger_kwargs:
    name: null
    project: null
